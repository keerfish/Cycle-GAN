{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87815032-9773-41ef-9cae-c3e0bf6ae499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.nn.modules.utils import _ntuple\n",
    "\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import os , itertools\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc4244-a413-4ab1-88d0-151a99545968",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':1,\n",
    "    'input_size':256,\n",
    "    'resize_scale':286,\n",
    "    'resize':128,\n",
    "    'crop_size':256,\n",
    "    'fliplr':True,\n",
    "    #model params\n",
    "    'num_epochs':100,\n",
    "    'decay_epoch':100,\n",
    "    'save_epoch': 70,\n",
    "    'ngf':32,   #number of generator filters\n",
    "    'ndf':64,   #number of discriminator filters\n",
    "    'num_resnet':6, #number of resnet blocks\n",
    "    'lrG':0.0002,    #learning rate for generator\n",
    "    'lrD':0.0002,    #learning rate for discriminator\n",
    "    'beta1':0.5 ,    #beta1 for Adam optimizer\n",
    "    'beta2':0.999 ,  #beta2 for Adam optimizer\n",
    "    'lambdaA':10 ,   #lambdaA for cycle loss\n",
    "    'lambdaB':10  ,  #lambdaB for cycle loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0430b8-9b1e-48f1-bb43-3c94ae6efa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1eb25f-3e8b-45ee-acf4-1e7d3fcfc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"./vangogh2photo\"))\n",
    "data_dir = './vangogh2photo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1a921-5d73-4231-b1b9-70e2d5be328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d2ead-df11-4f3b-93ba-a8c86f8759ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dba125-f0d5-477f-8850-7564073787dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cd8ba-ca85-4c5e-a0b8-38b2ccc238c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, subfolder='train', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.resize_scale = resize_scale\n",
    "        self.crop_size = crop_size\n",
    "        self.fliplr = fliplr\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn).convert('RGB')\n",
    "\n",
    "        # preprocessing\n",
    "        if self.resize_scale:\n",
    "            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n",
    "\n",
    "        if self.crop_size:\n",
    "            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            img = img.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
    "        if self.fliplr:\n",
    "            if random.random() < 0.5:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e4992-c397-487d-905f-cc012347928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMyData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, subfolder='train', transform=None, crop_size=None, fliplr=False):\n",
    "        super(GetMyData, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Load Image\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        imgnpz = np.load(img_fn, mmap_mode='r', allow_pickle=True)\n",
    "        image = imgnpz['arr_0']\n",
    "        \n",
    "        #Preprocessing\n",
    "        #img = numpy.array(img)\n",
    "        imarray = numpy.array(image)\n",
    "        iim=image\n",
    "        \n",
    "        #Preprocessing\n",
    "        \n",
    "        if self.crop_size:\n",
    "            \n",
    "            x = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            y = random.randint(0, params['input_size'] - self.crop_size + 1)\n",
    "            \n",
    "            #iim = im.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
    "            \n",
    "            iim=torch.from_numpy(imarray)\n",
    "            iim=iim[x:x + self.crop_size,y:y+ self.crop_size,:]\n",
    "\n",
    "            \n",
    "    \n",
    "        if self.transform is not None:\n",
    "            iim=torch.from_numpy(imarray)\n",
    "            \n",
    "            aaa=imarray[:,:,0]\n",
    "            aaa0 = self.transform(aaa)\n",
    "               \n",
    "            iim = aaa0[...,np.newaxis]\n",
    "\n",
    "            for i in range (1,params['stack_num']):   \n",
    "                 \n",
    "                aaa=imarray[:,:,i]\n",
    "                aaa1 = self.transform(aaa)\n",
    "               \n",
    "                aaa1 = aaa1[...,np.newaxis]\n",
    "                iim=np.concatenate((iim,aaa1),3)\n",
    "\n",
    "        return iim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e7626-0f02-4c44-a0fb-7c075ff9cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_result(real_image, gen_image, recon_image, epoch, save=False,  show=True, fig_size=(15, 15)):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=fig_size)\n",
    "    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n",
    "            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n",
    "    for ax, img in zip(axes.flatten(), imgs):\n",
    "        ax.axis('off')\n",
    "        #ax.set_adjustable('box-forced')\n",
    "        # Scale to 0-255\n",
    "        img = img.squeeze()\n",
    "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
    "        ax.imshow(img, cmap=None, aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    title = 'Epoch {0}'.format(epoch + 1)\n",
    "    fig.text(0.5, 0.04, title, ha='center')\n",
    "    \n",
    "    # save figure\n",
    "    if save:\n",
    "        save_fn = 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81f072-0722-43c1-9023-a46918cee30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(im_list, save_dir, epoch_num, save_mode_on=True):\n",
    "    \"\"\"\n",
    "        Pytorch conv2d uses input & output dimensions as: (N, C, H, W).\n",
    "        To be able to plot the generated images, torch tensors must be converted back to (W,H,C)\n",
    "        and transferred back into the local memory by .cpu() function\n",
    "    \"\"\"\n",
    "\n",
    "    #A list that holds the necessary plot titles\n",
    "    titles = ['Real-B', 'Fake-A (B->A)', 'Recon-B (B->A->B)', 'Identity-A (A->A)']\n",
    "\n",
    "    im_idx = 0\n",
    "    fig, axarr = plt.subplots(1,4, figsize=(12, 12))\n",
    "\n",
    "    for j in range(4):\n",
    "\n",
    "        im = im_list[im_idx].squeeze().T\n",
    "        im = (im + 1) / 2.0\n",
    "        imm=im\n",
    "        axarr[j].axis('off')\n",
    "        axarr[j].imshow(imm.detach().cpu())\n",
    "        axarr[j].set_title(titles[im_idx], fontweight=\"bold\")\n",
    "\n",
    "        im_idx = im_idx + 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_mode_on:\n",
    "        plt.savefig(os.path.join(save_dir, 'epoch-{}.png'.format(epoch_num)))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdcb93-fc14-478e-a9e6-eb08639afe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(torch.nn.Module):\n",
    "    def __init__(self,num_filter,kernel_size=3,stride=1,padding=0):\n",
    "        super(ResnetBlock,self).__init__()\n",
    "        conv1 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
    "        conv2 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
    "        bn = torch.nn.InstanceNorm2d(num_filter)\n",
    "        relu = torch.nn.ReLU(True)\n",
    "        pad = torch.nn.ReflectionPad2d(1)\n",
    "        \n",
    "        self.resnet_block = torch.nn.Sequential(\n",
    "            pad,\n",
    "            conv1,\n",
    "            bn,\n",
    "            relu,\n",
    "            pad,\n",
    "            conv2,\n",
    "            bn\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.resnet_block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab7d22-f406-457c-b2a7-e613c8443084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f7b9a-b3ea-4ae7-ac74-90e258eb72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,output_padding=1,activation='relu',batch_norm=True):\n",
    "        super(DeconvBlock,self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose2d(input_size,output_size,kernel_size,stride,padding,output_padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "    def forward(self,x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8db6a-d4cf-4220-85a4-b3491157ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self,input_dim,num_filter,output_dim,num_resnet):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        #Reflection padding\n",
    "        self.pad = torch.nn.ReflectionPad2d(3)\n",
    "        #Encoder\n",
    "        self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=7,stride=1,padding=0)\n",
    "        self.conv2 = ConvBlock(num_filter,num_filter*2)\n",
    "        self.conv3 = ConvBlock(num_filter*2,num_filter*4)\n",
    "        #Resnet blocks\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(num_resnet):\n",
    "            self.resnet_blocks.append(ResnetBlock(num_filter*4))\n",
    "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
    "        #Decoder\n",
    "        self.deconv1 = DeconvBlock(num_filter*4,num_filter*2)\n",
    "        self.deconv2 = DeconvBlock(num_filter*2,num_filter)\n",
    "        self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=7,stride=1,padding=0,activation='tanh',batch_norm=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #Encoder\n",
    "        enc1 = self.conv1(self.pad(x))\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        #Resnet blocks\n",
    "        res = self.resnet_blocks(enc3)\n",
    "        #Decoder\n",
    "        dec1 = self.deconv1(res)\n",
    "        dec2 = self.deconv2(dec1)\n",
    "        out = self.deconv3(self.pad(dec2))\n",
    "        return out\n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "            if isinstance(m,DeconvBlock):\n",
    "                torch.nn.init.normal_(m.deconv.weight,mean,std)\n",
    "            if isinstance(m,ResnetBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
    "                torch.nn.init.constant_(m.conv.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047549e9-71ac-486e-8573-c66c1cd23b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,input_dim,num_filter,output_dim):\n",
    "        super(Discriminator,self).__init__()\n",
    "        conv1 = ConvBlock(input_dim,num_filter,kernel_size=4,stride=2,padding=1,activation='lrelu',batch_norm=False)\n",
    "        conv2 = ConvBlock(num_filter,num_filter*2,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv3 = ConvBlock(num_filter*2,num_filter*4,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
    "        conv4 = ConvBlock(num_filter*4,num_filter*8,kernel_size=4,stride=1,padding=1,activation='lrelu')\n",
    "        conv5 = ConvBlock(num_filter*8,output_dim,kernel_size=4,stride=1,padding=1,activation='no_act',batch_norm=False)\n",
    "        self.conv_blocks = torch.nn.Sequential(\n",
    "            conv1,\n",
    "            conv2,\n",
    "            conv3,\n",
    "            conv4,\n",
    "            conv5\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.conv_blocks(x)\n",
    "        return out\n",
    "        \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                torch.nn.init.normal_(m.conv.weight.data,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa8e72-9115-4345-867b-a3024e0c8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for windows systems\n",
    "\n",
    "def manage_folders_mac():\n",
    "\n",
    "    currentDT = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "    #cur_dir = os.getcwd()\n",
    "    \n",
    "    cur_dir='./'\n",
    "\n",
    "    if not os.path.isdir(os.path.join(cur_dir, 'Output')):\n",
    "        os.mkdir(os.path.join(cur_dir, 'Output'))\n",
    "\n",
    "    output_folder = os.path.join(cur_dir, 'Output')\n",
    "    output_folder = os.path.join(output_folder, currentDT)\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "    graph_save_dir = os.path.join(output_folder, 'loss-graphs')\n",
    "    if not os.path.isdir(graph_save_dir):\n",
    "        os.mkdir(graph_save_dir)\n",
    "\n",
    "    im_save_dir = os.path.join(output_folder, 'generated-images')\n",
    "    if not os.path.isdir(im_save_dir):\n",
    "        os.mkdir(im_save_dir)\n",
    "\n",
    "    tr_im_save_dir = os.path.join(im_save_dir, 'train')\n",
    "    if not os.path.isdir(tr_im_save_dir):\n",
    "        os.mkdir(tr_im_save_dir)\n",
    "\n",
    "    te_im_save_dir = os.path.join(im_save_dir, 'te')\n",
    "    if not os.path.isdir(te_im_save_dir):\n",
    "        os.mkdir(te_im_save_dir)\n",
    "\n",
    "    model_save_dir = os.path.join(output_folder, 'saved-models')\n",
    "    if not os.path.isdir(model_save_dir):\n",
    "        os.mkdir(model_save_dir)\n",
    "\n",
    "    # Check if the directories exist\n",
    "    assert(os.path.isdir(im_save_dir)), 'Check your im_save_dir path.'\n",
    "    assert(os.path.isdir(graph_save_dir)), 'Check your graph_save_dir path.'\n",
    "\n",
    "    print('-----Directories to save the output-----\\nTrain Fake Images: {}\\nTest Fake Images: {}\\nLosses: {}\\nModel: {}'.format(tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir))\n",
    "\n",
    "    return tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334387a7-c66f-4077-bf8f-6b5e27c7ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for linux\n",
    "def manage_folders():\n",
    "\n",
    "    currentDT = datetime.datetime.now().strftime(\"%Y_%m_%d-%H:%M\")\n",
    "\n",
    "    cur_dir = os.getcwd()\n",
    "\n",
    "    if not os.path.isdir(os.path.join(cur_dir, 'Output')):\n",
    "        os.mkdir(os.path.join(cur_dir, 'Output'))\n",
    "\n",
    "    output_folder = os.path.join(cur_dir, 'Output')\n",
    "    output_folder = os.path.join(output_folder, currentDT)\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "    graph_save_dir = os.path.join(output_folder, 'loss-graphs')\n",
    "    if not os.path.isdir(graph_save_dir):\n",
    "        os.mkdir(graph_save_dir)\n",
    "\n",
    "    im_save_dir = os.path.join(output_folder, 'generated-images')\n",
    "    if not os.path.isdir(im_save_dir):\n",
    "        os.mkdir(im_save_dir)\n",
    "\n",
    "    tr_im_save_dir = os.path.join(im_save_dir, 'train')\n",
    "    if not os.path.isdir(tr_im_save_dir):\n",
    "        os.mkdir(tr_im_save_dir)\n",
    "\n",
    "    te_im_save_dir = os.path.join(im_save_dir, 'te')\n",
    "    if not os.path.isdir(te_im_save_dir):\n",
    "        os.mkdir(te_im_save_dir)\n",
    "\n",
    "    model_save_dir = os.path.join(output_folder, 'saved-models')\n",
    "    if not os.path.isdir(model_save_dir):\n",
    "        os.mkdir(model_save_dir)\n",
    "\n",
    "    # Check if the directories exist\n",
    "    assert(os.path.isdir(im_save_dir)), 'Check your im_save_dir path.'\n",
    "    assert(os.path.isdir(graph_save_dir)), 'Check your graph_save_dir path.'\n",
    "\n",
    "    print('-----Directories to save the output-----\\nTrain Fake Images: {}\\nVal Fake Images: {}\\nLosses: {}\\nModel: {}'.format(tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir))\n",
    "\n",
    "    return tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1115d-f5e4-4dfb-a626-fc105979d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=params['input_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684edb9-7bed-4979-a209-7a8077ae9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "test_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "test_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2cd4a-8c9f-4844-b0f4-019c2120204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tryimgA = train_data_A[99]\n",
    "tryimgB = train_data_B[9]\n",
    "tryimgAt = test_data_A[19]\n",
    "tryimgBt = test_data_B[9]\n",
    "print(tryimgA.shape)\n",
    "print(tryimgB.shape)\n",
    "print(tryimgAt.shape)\n",
    "print(tryimgBt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6701b0-d9bc-4e4f-abba-985e4373de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd886b-1cf8-4182-8043-e71774ee6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_A_data = test_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
    "test_real_B_data = test_data_B.__getitem__(96).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf597bb8-49b8-4f1e-a267-fd325d63f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_real_A_data.shape)\n",
    "print(test_real_B_data.shape)\n",
    "generator_A2B = Generator(3,params['ngf'],3,params['num_resnet'])\n",
    "generator_B2A = Generator(3,params['ngf'],3,params['num_resnet'])\n",
    "print(generator_A2B(test_real_A_data).shape)\n",
    "print(generator_B2A(generator_A2B(test_real_A_data)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b24db1-9abd-4ca4-910a-b725cede451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_loss(reconstructed_images, real_images):\n",
    "\n",
    "    return F.l1_loss(reconstructed_images, real_images)\n",
    "    \n",
    "def identity_loss(inputs, real_images):\n",
    "\n",
    "    return F.l1_loss(inputs, real_images)\n",
    "    \n",
    "def gan_loss(inputs, is_real):\n",
    "\n",
    "    if is_real:\n",
    "\n",
    "        return F.mse_loss(inputs, torch.ones(inputs.shape).to(device))\n",
    "    else:\n",
    "        return F.mse_loss(inputs, torch.zeros(inputs.shape).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25725a-88de-4a78-ab69-5d78ad63f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=cycle_loss(generator_A2B(test_real_A_data),test_real_A_data)\n",
    "print(test)\n",
    "#for i, (data_A, data_B) in enumerate(zip(train_data_loader_A,train_data_loader_B)):\n",
    "        \n",
    "        # input image data\n",
    "#    data_A = data_A.to(device)\n",
    "#    print(data_A.shape)\n",
    "#    data_B = data_B.to(device)\n",
    "#    print(data_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f397a7f-25ef-4bcf-8ff2-3a2384d8a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cycleGAN(nn.Module):\n",
    "\n",
    "    def __init__(self, learning_rate=2e-4):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        #params['input_size']\n",
    "\n",
    "        # Loss function coeffs\n",
    "        self.LAMBDA_CYCLE = 10.5\n",
    "        self.LAMBDA_ID = 0.5\n",
    "        self.LAMBDA_CROSS = 0.35   #0.3works\n",
    "\n",
    "        self.beta1 = 0.5     #beta1 for Adam optimizer\n",
    "        self.beta2 = 0.999  #beta2 for Adam optimizer\n",
    "        \n",
    "        \n",
    "        self.counter = 0\n",
    "        self.counter1 = 0\n",
    "        self.progress = []\n",
    "        self.progress1 = []\n",
    "        \n",
    "        # Image pool parameter\n",
    "        pool_size = 50\n",
    "\n",
    "        # Discriminate test and train behaviour\n",
    "        self.is_training = True\n",
    "        self.save_losses = False\n",
    "\n",
    "        # Initialize the image pools for both domains.\n",
    "        self.fake_A_pool = ImagePool(pool_size)\n",
    "        self.fake_B_pool = ImagePool(pool_size)\n",
    "\n",
    "# Create dictionaries to save the entire loss progress\n",
    "                \n",
    "        self.tr_gen_loss_dict = {\n",
    "            'loss_gen_A2B': [],\n",
    "            'loss_gen_B2A': [],\n",
    "            \n",
    "            'loss_iden_A2B': [],\n",
    "            'loss_iden_B2A': [],\n",
    "            \n",
    "            'loss_cycle_B2A2B': [],\n",
    "            'loss_gen_total': []\n",
    "        }\n",
    "        self.tr_dis_loss_dict = {\n",
    "            'loss_dis_B': [],\n",
    "            'loss_dis_A': [],\n",
    "            'loss_dis_total': []\n",
    "        }\n",
    "        self.te_gen_loss_dict = {\n",
    "            'loss_gen_A2B': [],\n",
    "            'loss_gen_B2A': [],\n",
    "            \n",
    "            'loss_iden_A2B': [],\n",
    "            'loss_iden_B2A': [],\n",
    "            \n",
    "            'loss_cycle_B2A2B': [],\n",
    "            'loss_gen_total': []\n",
    "        }\n",
    "        self.te_dis_loss_dict = {\n",
    "            'loss_dis_B': [],\n",
    "            'loss_dis_A': [],\n",
    "            'loss_dis_total': []\n",
    "        }\n",
    "\n",
    "        self.im_list = []\n",
    "        \n",
    "        self.generator_A2B = Generator(3,params['ngf'],3,params['num_resnet'])\n",
    "        self.generator_B2A = Generator(3,params['ngf'],3,params['num_resnet'])\n",
    "        \n",
    "        self.discriminator_A = Discriminator(3,params['ndf'],1)\n",
    "        self.discriminator_B = Discriminator(3,params['ndf'],1)\n",
    "        \n",
    "        self.optimizer_total = torch.optim.Adam(itertools.chain(self.generator_A2B.parameters(), self.generator_B2A.parameters()), lr=self.learning_rate, betas=(params['beta1'], params['beta2']))\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.generator_A2B.parameters(), self.generator_B2A.parameters()), lr=self.learning_rate, betas=(params['beta1'], params['beta2']))\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.discriminator_A.parameters(), self.discriminator_B.parameters()), lr=self.learning_rate, betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "    def forward(self, real_A, real_B):\n",
    "\n",
    "        fake_B2A = self.generator_B2A(real_B)\n",
    "        fake_A2B = self.generator_A2B(real_A)\n",
    "        \n",
    "        recon_A2B = self.generator_A2B(fake_B2A)\n",
    "        recon_B2A = self.generator_B2A(fake_A2B)\n",
    "        \n",
    "        identity_A2B = self.generator_A2B(real_B)\n",
    "        identity_B2A = self.generator_B2A(real_A)\n",
    "\n",
    "        self.im_list = [real_B,fake_B2A,recon_A2B,identity_B2A]\n",
    "\n",
    "        return fake_A2B, recon_A2B, fake_B2A, recon_B2A, identity_A2B, identity_B2A\n",
    "\n",
    "    def backward_G(self, real_A, real_B, fake_A2B, fake_B2A, recon_A2B, recon_B2A, identity_A2B, identity_B2A):\n",
    "        \n",
    "        if self.is_training:\n",
    "          \n",
    "            self.set_requires_grad([self.discriminator_B,self.discriminator_A], False)\n",
    "      \n",
    "            self.optimizer_G.zero_grad()\n",
    "\n",
    "        loss_identity_A2B = identity_loss(identity_A2B, real_B)\n",
    "        loss_identity_B2A = identity_loss(identity_B2A, real_A)\n",
    "\n",
    "                                            \n",
    "        loss_gan_gen_B2A = gan_loss(self.discriminator_A(fake_B2A), True)\n",
    "        loss_gan_gen_A2B = gan_loss(self.discriminator_B(fake_A2B), True) \n",
    "                                                                          \n",
    "        loss_cycle_B2A2B = cycle_loss(recon_A2B, real_B)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_gen_total = loss_gan_gen_A2B + loss_gan_gen_B2A \\\n",
    "            + loss_cycle_B2A2B * self.LAMBDA_CYCLE \\\n",
    "            + (loss_identity_A2B + loss_identity_B2A) * self.LAMBDA_ID \n",
    "        \n",
    "        loss_plot=loss_gen_total\n",
    "        loss_plot1=loss_gan_gen_A2B\n",
    "        loss_plot2=loss_gan_gen_B2A\n",
    "        loss_plot3=loss_cycle_B2A2B\n",
    "\n",
    "        self.counter += 1;\n",
    "        \n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss_plot.item())\n",
    "            self.progress.append(loss_plot1.item())\n",
    "            self.progress.append(loss_plot2.item())\n",
    "            self.progress.append(loss_plot3.item())\n",
    "            pass\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        if self.is_training:\n",
    "            # Calculate gradients\n",
    "            loss_gen_total.backward()\n",
    "\n",
    "            self.optimizer_G.step()\n",
    "            \n",
    "        if self.save_losses:\n",
    "            if self.is_training:\n",
    "                self.tr_gen_loss_dict['loss_gen_A2B'].append(loss_gan_gen_A2B.item())\n",
    "                self.tr_gen_loss_dict['loss_gen_B2A'].append(loss_gan_gen_B2A.item())\n",
    "                self.tr_gen_loss_dict['loss_iden_A2B'].append(loss_identity_A2B.item())\n",
    "                \n",
    "                self.tr_gen_loss_dict['loss_cycle_B2A2B'].append(loss_cycle_B2A2B.item())\n",
    "                self.tr_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
    "            else:\n",
    "                self.te_gen_loss_dict['loss_gen_A2B'].append(loss_gan_gen_A2B.item())\n",
    "                self.te_gen_loss_dict['loss_gen_B2A'].append(loss_gan_gen_B2A.item())\n",
    "                self.te_gen_loss_dict['loss_iden_A2B'].append(loss_identity_A2B.item())\n",
    "           \n",
    "                self.te_gen_loss_dict['loss_cycle_B2A2B'].append(loss_cycle_B2A2B.item())\n",
    "                self.te_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
    "    \n",
    "    def backward_D(self, real_A, real_B, fake_A2B, fake_B2A):\n",
    "\n",
    "        fake_A2B = self.fake_B_pool.query(fake_A2B)\n",
    "        fake_B2A = self.fake_A_pool.query(fake_B2A)\n",
    "\n",
    "        if self.is_training:\n",
    "            self.set_requires_grad([self.discriminator_B,self.discriminator_A], True)\n",
    "            self.optimizer_D.zero_grad()  \n",
    "\n",
    "        loss_gan_dis_A_real = gan_loss(self.discriminator_A(real_A), True)\n",
    "        loss_gan_dis_A_fake = gan_loss(self.discriminator_A(fake_B2A.detach()), False)   \n",
    "                                                          \n",
    "        loss_gan_dis_B_real = gan_loss(self.discriminator_B(real_B), True)\n",
    "        loss_gan_dis_B_fake = gan_loss(self.discriminator_B(fake_A2B.detach()), False) # Detach added\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_dis_A = (loss_gan_dis_A_real + loss_gan_dis_A_fake) * 0.5\n",
    "        \n",
    "        loss_dis_B = (loss_gan_dis_B_real + loss_gan_dis_B_fake) * 0.5\n",
    "\n",
    "        loss_dis_total = loss_dis_A + loss_dis_B\n",
    "        \n",
    "        loss_plott=loss_dis_total\n",
    "        loss_plott1=loss_dis_A\n",
    "        loss_plott2=loss_dis_B\n",
    "        \n",
    "        \n",
    "        self.counter1 += 1;\n",
    "\n",
    "        if (self.counter1 % 10 == 0):\n",
    "            self.progress1.append(loss_plott.item())\n",
    "            self.progress1.append(loss_plott1.item())\n",
    "            self.progress1.append(loss_plott2.item())\n",
    "\n",
    "            pass\n",
    "        if (self.counter1 % 1000 == 0):\n",
    "            print(\"counter1 = \", self.counter1)\n",
    "            pass\n",
    "\n",
    "\n",
    "        if self.is_training:\n",
    "            # Calculate gradients\n",
    "            loss_dis_total.backward()\n",
    "            # Update D_A and D_B's weights\n",
    "            self.optimizer_D.step()\n",
    "\n",
    "        # Save train and test losses separately\n",
    "        if self.save_losses:\n",
    "            if self.is_training:\n",
    "                self.tr_dis_loss_dict['loss_dis_B'].append(loss_dis_B.item())\n",
    "                self.tr_dis_loss_dict['loss_dis_A'].append(loss_dis_A.item())\n",
    "                self.tr_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
    "            else:\n",
    "                self.te_dis_loss_dict['loss_dis_B'].append(loss_dis_B.item())\n",
    "                self.te_dis_loss_dict['loss_dis_A'].append(loss_dis_A.item())\n",
    "                self.te_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
    "\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "      \n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "                    \n",
    "\n",
    "    def plot_progress(self):\n",
    "        \n",
    "        df = pandas.DataFrame(self.progress, columns=['loss_plot'])\n",
    "        df1=pandas.concat([df, pandas.DataFrame(columns = [ 'loss_plot1'])])\n",
    "        df1=pandas.concat([df1, pandas.DataFrame(columns = [ 'loss_plot2'])])\n",
    "        df1=pandas.concat([df1, pandas.DataFrame(columns = [ 'loss_plot3'])])\n",
    "\n",
    "        fig,ax= plt.subplots()\n",
    "        \n",
    "        ax=df1[['loss_plot','loss_plot1','loss_plot2','loss_plot3']].plot.area(ax=ax)\n",
    "\n",
    "        ax.autoscale()\n",
    "        ax.set_ylim(0,None)\n",
    "        ax.margins(x=0)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self, real_A, real_B):\n",
    "\n",
    "        # Forward\n",
    "        fake_A2B, recon_A2B, fake_B2A, recon_B2A, identity_A2B, identity_B2A = self.forward(real_A, real_B)  # compute fake images and reconstruction images.\n",
    "        # G_A and G_B\n",
    "        self.backward_G(real_A, real_B, fake_A2B, fake_B2A, recon_A2B, recon_B2A, identity_A2B, identity_B2A)  # calculate gradients for G_A and G_B\n",
    "        # D_A and D_B\n",
    "        self.backward_D(real_A, real_B, fake_A2B, fake_B2A)  # To-Do: Query fake images from the pool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36973e-506f-4171-bb8c-8985634a42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset_A, train_dataset_B,test_dataset_A,test_dataset_B ,epochs, device):\n",
    " \n",
    "    model = cycleGAN().to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('Epoch', epoch+1, '------------------')\n",
    "        \n",
    "\n",
    "        # Training\n",
    "        temp = 1\n",
    "        model.is_training = True\n",
    "        \n",
    "        for i, (data_A, data_B) in enumerate(zip(train_dataset_A,train_dataset_B)):\n",
    "        \n",
    "        # input image data\n",
    "        \n",
    "            data_A = data_A.to(device)\n",
    "            data_B = data_B.to(device)\n",
    "      \n",
    "\n",
    "            # Save loss values at the end of each epoch\n",
    "            if temp == train_dataset_A.__len__():\n",
    "                model.save_losses = True\n",
    "\n",
    "            model.optimize_parameters(data_A, data_B)\n",
    "\n",
    "            temp = temp+1\n",
    "            \n",
    "        #model.plot_progress()\n",
    "\n",
    "        print('Tr - Total Generator Loss:', np.round(model.tr_gen_loss_dict['loss_gen_total'][-1], decimals=3))\n",
    "        print('Tr - Total Dicriminator Loss:', np.round(model.tr_dis_loss_dict['loss_dis_total'][-1], decimals=3))\n",
    "\n",
    "        model.save_losses = False\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            \n",
    "            print_images(model.im_list, tr_im_save_dir, str(epoch), save_mode_on=True)\n",
    "\n",
    "        # test\n",
    "        with torch.set_grad_enabled(False):\n",
    "\n",
    "            temp = 1\n",
    "            model.is_training = False\n",
    "            for i, (data_A, data_B) in enumerate(zip(test_dataset_A,test_dataset_B)):\n",
    "\n",
    "                data_A = data_A.to(device)\n",
    "                data_B = data_B.to(device)\n",
    "\n",
    "                if temp == test_dataset_A.__len__():\n",
    "                    model.save_losses = True\n",
    "\n",
    "                model.optimize_parameters(data_A, data_B)\n",
    "\n",
    "                temp = temp+1\n",
    "\n",
    "            print('----')\n",
    "            print('te - Total Generator Loss:', np.round(model.te_gen_loss_dict['loss_gen_total'][-1], decimals=3))\n",
    "            print('te - Total Dicriminator Loss:', np.round(model.te_dis_loss_dict['loss_dis_total'][-1], decimals=3))\n",
    "\n",
    "            model.save_losses = False\n",
    "\n",
    "            print_images(model.im_list, te_im_save_dir, str(epoch), save_mode_on=True)\n",
    "           \n",
    "        \n",
    "            \n",
    "            test_real_B = test_real_B_data.cuda()\n",
    "            test_real_A = test_real_A_data.cuda()\n",
    "    \n",
    "            Results = model.forward(test_real_A,test_real_B)\n",
    "    \n",
    "        \n",
    "            test_fake_B = Results[0] #fake_A2B\n",
    "    \n",
    "            test_recon_b = Results[1] #recon_A2B\n",
    "    \n",
    "            test_fake_A = Results[2] #fake_B2A\n",
    "    \n",
    "            test_recon_A = Results[3] #recon_B2A\n",
    "\n",
    "            #test_identi_B = Results[4] #identity_A2B\n",
    "\n",
    "            #test_identi_A = Results[5] #identity_B2A\n",
    "            \n",
    "            plot_train_result([test_real_B, test_real_A], [test_fake_A, test_fake_B], [test_recon_B, test_recon_A],\n",
    "                            epoch, save=True)\n",
    "        \n",
    "            \n",
    "            if epoch  > params['save_epoch']:\n",
    "                torch.save(model,os.path.join(model_save_dir,'model_%03d.pth'%epoch))\n",
    "    \n",
    " \n",
    "    # Save gen and disc loss values to respective csv files.\n",
    "    df = pd.DataFrame.from_dict(model.tr_gen_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'tr_gen_losses.csv'), index=False)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(model.tr_dis_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'tr_dis_losses.csv'), index=False)\n",
    "    \n",
    "    # Save gen and disc loss values to respective csv files.\n",
    "    df = pd.DataFrame.from_dict(model.te_gen_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'te_gen_losses.csv'), index=False)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(model.te_dis_loss_dict)\n",
    "    df.to_csv(os.path.join(graph_save_dir, 'te_dis_losses.csv'), index=False)\n",
    "\n",
    "    # Save entire model architecture and params.\n",
    "    torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98f117-ff99-4788-9c8c-7ab8d8b650c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_im_save_dir, te_im_save_dir, graph_save_dir, model_save_dir = manage_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679aae3-cf7b-430b-9b54-1b0bba6c3d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_data_loader_A,train_data_loader_B,test_data_loader_A,test_data_loader_B,200, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c2a4a-5f06-4cc3-ad83-8d869b2278ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
